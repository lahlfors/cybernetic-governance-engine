# Sovereign Stack Configuration
# Rename this file to ".env"

# --- MODEL CONFIGURATION (Sovereign / Open Weights) ---

# Reasoning path: Risk Analyst, Verifier (safety-critical)
# Defaults to DeepSeek-R1-Distill-Qwen-32B (Sovereign)
MODEL_REASONING=deepseek-ai/DeepSeek-R1-Distill-Qwen-32B

# Governance path: Fast tasks (FSM, Classification)
MODEL_FAST=Qwen/Qwen2.5-7B-Instruct

# Consensus path: High-stakes validation (defaults to MODEL_REASONING)
MODEL_CONSENSUS=deepseek-ai/DeepSeek-R1-Distill-Qwen-32B

# --- INFERENCE INFRASTRUCTURE ---

# Option A: Local Split-Brain (Direct Connection)
# Default for Docker Compose / Local Development
VLLM_REASONING_API_BASE=http://localhost:8000/v1
VLLM_FAST_API_BASE=http://localhost:8001/v1

# Option B: GKE Inference Gateway (Unified Endpoint)
# Set this for Production to enable Priority Handling & Autoscaling.
# If set, VLLM_REASONING_API_BASE and VLLM_FAST_API_BASE are ignored.
# VLLM_GATEWAY_URL=http://<GATEWAY_IP>/v1

# --- SERVICE CONFIGURATION ---
PORT=8080
REDIS_URL=redis://localhost:6379

# --- SIDECARS ---
# OPA Policy Engine
OPA_URL=http://localhost:8181/v1/data/finance/allow
OPA_AUTH_TOKEN=

# Python Sandbox (Computer Use)
SANDBOX_URL=http://localhost:8081/execute

# --- TELEMETRY & OBSERVABILITY ---

# Langfuse Configuration (Self-Hosted on Cloud Run)
# Leave host blank to use SaaS (https://cloud.langfuse.com)
LANGFUSE_HOST=https://<YOUR_LANGFUSE_HOST>
LANGFUSE_PUBLIC_KEY=<YOUR_LANGFUSE_PUBLIC_KEY>
LANGFUSE_SECRET_KEY=<YOUR_LANGFUSE_SECRET_KEY>

# OpenTelemetry (Cold Tier)
# Configured automatically by telemetry.py if LANGFUSE vars are set.
# OTEL_EXPORTER_OTLP_ENDPOINT can be used to override.
TRACE_SAMPLING_RATE=0.01

# Cold Tier Storage (Parquet)
# If set, Parquet files are written to GCS. If unset, defaults to local disk (logs/cold_tier).
COLD_TIER_GCS_BUCKET=<YOUR_GCS_BUCKET_NAME>
COLD_TIER_GCS_PREFIX=cold_tier

# --- EXTERNAL TOOLS ---

# MCP Configuration (AlphaVantage)
# Mode: 'stdio' (local execution via uvx) or 'sse' (remote server)
MCP_MODE=stdio
ALPHAVANTAGE_API_KEY=<YOUR_ALPHAVANTAGE_KEY>

# Hugging Face (for gated model access)
HUGGING_FACE_HUB_TOKEN=<YOUR_HF_TOKEN>

# --- GOOGLE CLOUD (Optional / Legacy) ---
# Required only if using GSM for secrets or Vertex AI fallbacks
GOOGLE_CLOUD_PROJECT=<YOUR_PROJECT_ID>
GOOGLE_CLOUD_LOCATION=<YOUR_PROJECT_LOCATION>
