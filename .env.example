# Sovereign Stack Configuration
# Rename this file to ".env"

# --- MODEL CONFIGURATION (Sovereign / Open Weights) ---

# Reasoning path: Risk Analyst, Verifier (safety-critical)
MODEL_REASONING=gemini-2.5-pro

# Consensus path: High-stakes validation (defaults to MODEL_REASONING)
MODEL_CONSENSUS=gemini-2.5-pro

# Vertex AI Configuration
GOOGLE_GENAI_USE_VERTEXAI=1
GOOGLE_CLOUD_PROJECT=<YOUR_PROJECT_ID>
GOOGLE_CLOUD_LOCATION=<YOUR_PROJECT_LOCATION>
GOOGLE_CLOUD_ZONE=<YOUR_PROJECT_ZONE>  # Optional: For Zonal GKE clusters (e.g., us-central1-a)
GOOGLE_CLOUD_STORAGE_BUCKET=<YOUR_STORAGE_BUCKET>  # Only required for deployment on Agent Engine

# Governance & Policy Registry (Offline Pipeline)
POLICY_REGISTRY_BUCKET=<YOUR_POLICY_BUCKET_NAME>
STAMP_CONFIG_BLOB=current_stamp_spec.yaml
OUTPUT_ARTIFACT_URI=gs://local/artifacts/latest_evidence.json

# Policy Engine (OPA)
OPA_URL=http://localhost:8181/v1/data/finance/allow

# Hybrid Inference (vLLM)
# For sovereign/open weights deployments, configure separate endpoints for tiered models
VLLM_BASE_URL=http://localhost:8000/v1
VLLM_API_KEY=EMPTY
VLLM_FAST_API_BASE=http://localhost:8000/v1
VLLM_REASONING_API_BASE=http://localhost:8001/v1

# Cold Tier Observability (OTLP/Arrow)
# If set, spans are exported via OTLP (e.g. to a Collector or Honeycomb/Langfuse)
# If unset, Cold Tier is disabled (NoOp)
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318/v1/traces
OTEL_EXPORTER_OTLP_HEADERS=

# Tiered Observability (Cold Storage)
# If set, Parquet files are written to GCS. If unset, defaults to local disk (logs/cold_tier).
COLD_TIER_GCS_BUCKET=<YOUR_GCS_BUCKET_NAME>
COLD_TIER_GCS_PREFIX=cold_tier

# Langfuse Configuration (Hot Tier / Agent Tracing)
LANGFUSE_PUBLIC_KEY=<YOUR_PUBLIC_KEY>
LANGFUSE_SECRET_KEY=<YOUR_SECRET_KEY>
LANGFUSE_HOST=https://cloud.langfuse.com

# OpenTelemetry (Cold Tier)
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318/v1/traces
OTEL_EXPORTER_OTLP_HEADERS=

# Cold Tier Storage (Parquet)
COLD_TIER_GCS_BUCKET="local-bucket"
COLD_TIER_GCS_PREFIX="cold_tier"

# --- SERVICE CONFIGURATION ---
PORT=8080
GOOGLE_APPLICATION_CREDENTIALS=  # Path to service account key (optional for local dev)

# MCP Configuration (AlphaVantage)
# Mode: 'stdio' (local execution via uvx) or 'sse' (remote server)
MCP_MODE=stdio
ALPHAVANTAGE_API_KEY=<YOUR_ALPHAVANTAGE_KEY>

# Hugging Face (for gated model access)
HUGGING_FACE_HUB_TOKEN=<YOUR_HF_TOKEN>
