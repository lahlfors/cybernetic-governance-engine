  File "/usr/local/lib/python3.12/site-packages/litellm/main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 501, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: NotFoundError: OpenAIException - The model `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` does not exist.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

{"timestamp": "2026-02-14 18:19:00,057", "severity": "WARNING", "name": "Graph.Adapters", "message": "\u26a0\ufe0f Failed to parse Execution Plan JSON: Expecting value: line 1 column 1 (char 0). Passing raw text.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "e443dd5d5e664f83", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,069", "severity": "INFO", "name": "EvaluatorNode", "message": "\ud83d\udee1\ufe0f Evaluator: Monitoring execution for execute_trade", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "6f2dc64017523f8f", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,074", "severity": "WARNING", "name": "EvaluatorNode", "message": "\ud83d\uded1 Evaluator Node Detected Violation! Sending Interrupt Signal.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "744bfe8fd02cc483", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,074", "severity": "WARNING", "name": "EvaluatorAgent", "message": "\ud83d\uded1 Evaluator Triggering Intervention: REJECTED: STPA Violation FIN-2: Agent must not execute trade if latency > 200ms; SR 11-7 Violation: Model Confidence 0.0 < 0.95.; ISO 42001 Policy Violation: OPA Denied Action.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "744bfe8fd02cc483", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,076", "severity": "INFO", "name": "EvaluatorNode", "message": "\u2696\ufe0f Evaluator Verdict: REJECTED -> Routing to execution_analyst", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "744bfe8fd02cc483", "trace_sampled": true}
--- [Graph] Calling Execution Analyst (Planner) ---
--- [Loop] Injecting Risk Feedback ---
{"timestamp": "2026-02-14 18:19:00,092", "severity": "WARNING", "name": "google_adk.google.adk.runners", "message": "Event from an unknown agent: data_analyst_agent, event id: 2e022edf-3ff9-48f7-b2fb-48d1eb97956f", "trace_id": "89db7d7ab446650b58cdabcbe4981a1e", "span_id": "1b066aa3904fc86b", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,092", "severity": "WARNING", "name": "google_adk.google.adk.runners", "message": "Event from an unknown agent: data_analyst_agent, event id: 7b1d468b-06b9-404e-b4fc-312c19fda378", "trace_id": "89db7d7ab446650b58cdabcbe4981a1e", "span_id": "1b066aa3904fc86b", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,093", "severity": "WARNING", "name": "google_adk.google.adk.runners", "message": "Event from an unknown agent: data_analyst_agent, event id: 65581701-4df7-431f-8142-5673f56285ff", "trace_id": "89db7d7ab446650b58cdabcbe4981a1e", "span_id": "1b066aa3904fc86b", "trace_sampled": true}
[92m18:19:00 - LiteLLM:INFO[0m: utils.py:3748 - 
LiteLLM completion() model= deepseek-ai/DeepSeek-R1-Distill-Qwen-32B; provider = openai
{"timestamp": "2026-02-14 18:19:00,102", "severity": "INFO", "name": "LiteLLM", "message": "\nLiteLLM completion() model= deepseek-ai/DeepSeek-R1-Distill-Qwen-32B; provider = openai", "trace_id": "89db7d7ab446650b58cdabcbe4981a1e", "span_id": "341068048172ff5c", "trace_sampled": true}
Exception in thread Thread-16 (_asyncio_thread_main):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 460, in make_openai_chat_completion_request
    raise e
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/usr/local/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/openai/_base_client.py", line 1884, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/openai/_base_client.py", line 1669, in request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` does not exist.', 'type': 'NotFoundError', 'param': 'model', 'code': 404}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/litellm/main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 404 - {'error': {'message': 'The model `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` does not exist.', 'type': 'NotFoundError', 'param': 'model', 'code': 404}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 435, in _asyncio_thread_main
    asyncio.run(_invoke_run_async())
  File "/usr/local/lib/python3.12/site-packages/nest_asyncio.py", line 30, in run
    return loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/nest_asyncio.py", line 98, in run_until_complete
    return f.result()
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/asyncio/futures.py", line 202, in result
    raise self._exception.with_traceback(self._exception_tb)
  File "/usr/local/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 428, in _invoke_run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 561, in run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 549, in _run_with_trace
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 778, in _exec_with_plugin
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 538, in execute
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 294, in run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/agents/llm_agent.py", line 468, in _run_async_impl
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 427, in run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 504, in _run_one_step_async
    async for llm_response in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 966, in _call_llm_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 949, in _call_llm_with_tracing
    async for llm_response in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 1184, in _run_and_handle_error
    raise model_error
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 1169, in _run_and_handle_error
    async for llm_response in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/models/lite_llm.py", line 2022, in generate_content_async
    response = await self.llm_client.acompletion(**completion_args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/google/adk/models/lite_llm.py", line 443, in acompletion
    return await acompletion(
           ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/utils.py", line 1915, in wrapper_async
    raise e
  File "/usr/local/lib/python3.12/site-packages/litellm/utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 501, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: NotFoundError: OpenAIException - The model `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` does not exist.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

{"timestamp": "2026-02-14 18:19:00,175", "severity": "WARNING", "name": "Graph.Adapters", "message": "\u26a0\ufe0f Failed to parse Execution Plan JSON: Expecting value: line 1 column 1 (char 0). Passing raw text.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "f48cdeeb0e3e890c", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,186", "severity": "INFO", "name": "EvaluatorNode", "message": "\ud83d\udee1\ufe0f Evaluator: Monitoring execution for execute_trade", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "d17617b2b7680db3", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,191", "severity": "WARNING", "name": "EvaluatorNode", "message": "\ud83d\uded1 Evaluator Node Detected Violation! Sending Interrupt Signal.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "d30f44c37381336b", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,192", "severity": "WARNING", "name": "EvaluatorAgent", "message": "\ud83d\uded1 Evaluator Triggering Intervention: REJECTED: STPA Violation FIN-2: Agent must not execute trade if latency > 200ms; SR 11-7 Violation: Model Confidence 0.0 < 0.95.; ISO 42001 Policy Violation: OPA Denied Action.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "d30f44c37381336b", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,195", "severity": "INFO", "name": "EvaluatorNode", "message": "\u2696\ufe0f Evaluator Verdict: REJECTED -> Routing to execution_analyst", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "d30f44c37381336b", "trace_sampled": true}
--- [Graph] Calling Execution Analyst (Planner) ---
--- [Loop] Injecting Risk Feedback ---
{"timestamp": "2026-02-14 18:19:00,212", "severity": "WARNING", "name": "google_adk.google.adk.runners", "message": "Event from an unknown agent: data_analyst_agent, event id: 2e022edf-3ff9-48f7-b2fb-48d1eb97956f", "trace_id": "7b075bb5b252667cb253230e667574f8", "span_id": "a4da0d852c0a14ed", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,212", "severity": "WARNING", "name": "google_adk.google.adk.runners", "message": "Event from an unknown agent: data_analyst_agent, event id: 7b1d468b-06b9-404e-b4fc-312c19fda378", "trace_id": "7b075bb5b252667cb253230e667574f8", "span_id": "a4da0d852c0a14ed", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,212", "severity": "WARNING", "name": "google_adk.google.adk.runners", "message": "Event from an unknown agent: data_analyst_agent, event id: 65581701-4df7-431f-8142-5673f56285ff", "trace_id": "7b075bb5b252667cb253230e667574f8", "span_id": "a4da0d852c0a14ed", "trace_sampled": true}
[92m18:19:00 - LiteLLM:INFO[0m: utils.py:3748 - 
LiteLLM completion() model= deepseek-ai/DeepSeek-R1-Distill-Qwen-32B; provider = openai
{"timestamp": "2026-02-14 18:19:00,219", "severity": "INFO", "name": "LiteLLM", "message": "\nLiteLLM completion() model= deepseek-ai/DeepSeek-R1-Distill-Qwen-32B; provider = openai", "trace_id": "7b075bb5b252667cb253230e667574f8", "span_id": "d288736b353fc853", "trace_sampled": true}
Exception in thread Thread-17 (_asyncio_thread_main):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 460, in make_openai_chat_completion_request
    raise e
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/usr/local/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/openai/_base_client.py", line 1884, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/openai/_base_client.py", line 1669, in request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` does not exist.', 'type': 'NotFoundError', 'param': 'model', 'code': 404}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/litellm/main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 404 - {'error': {'message': 'The model `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` does not exist.', 'type': 'NotFoundError', 'param': 'model', 'code': 404}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 435, in _asyncio_thread_main
    asyncio.run(_invoke_run_async())
  File "/usr/local/lib/python3.12/site-packages/nest_asyncio.py", line 30, in run
    return loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/nest_asyncio.py", line 98, in run_until_complete
    return f.result()
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/asyncio/futures.py", line 202, in result
    raise self._exception.with_traceback(self._exception_tb)
  File "/usr/local/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 428, in _invoke_run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 561, in run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 549, in _run_with_trace
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 778, in _exec_with_plugin
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 538, in execute
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 294, in run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/agents/llm_agent.py", line 468, in _run_async_impl
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 427, in run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 504, in _run_one_step_async
    async for llm_response in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 966, in _call_llm_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 949, in _call_llm_with_tracing
    async for llm_response in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 1184, in _run_and_handle_error
    raise model_error
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 1169, in _run_and_handle_error
    async for llm_response in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/models/lite_llm.py", line 2022, in generate_content_async
    response = await self.llm_client.acompletion(**completion_args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/google/adk/models/lite_llm.py", line 443, in acompletion
    return await acompletion(
           ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/utils.py", line 1915, in wrapper_async
    raise e
  File "/usr/local/lib/python3.12/site-packages/litellm/utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 501, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: NotFoundError: OpenAIException - The model `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` does not exist.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

{"timestamp": "2026-02-14 18:19:00,296", "severity": "WARNING", "name": "Graph.Adapters", "message": "\u26a0\ufe0f Failed to parse Execution Plan JSON: Expecting value: line 1 column 1 (char 0). Passing raw text.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "b7d0f61f08ba960b", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,306", "severity": "INFO", "name": "EvaluatorNode", "message": "\ud83d\udee1\ufe0f Evaluator: Monitoring execution for execute_trade", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "c790c2e7239a71c5", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,310", "severity": "WARNING", "name": "EvaluatorNode", "message": "\ud83d\uded1 Evaluator Node Detected Violation! Sending Interrupt Signal.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "67a287cd175de815", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,310", "severity": "WARNING", "name": "EvaluatorAgent", "message": "\ud83d\uded1 Evaluator Triggering Intervention: REJECTED: STPA Violation FIN-2: Agent must not execute trade if latency > 200ms; SR 11-7 Violation: Model Confidence 0.0 < 0.95.; ISO 42001 Policy Violation: OPA Denied Action.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "67a287cd175de815", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,313", "severity": "INFO", "name": "EvaluatorNode", "message": "\u2696\ufe0f Evaluator Verdict: REJECTED -> Routing to execution_analyst", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "67a287cd175de815", "trace_sampled": true}
--- [Graph] Calling Execution Analyst (Planner) ---
--- [Loop] Injecting Risk Feedback ---
{"timestamp": "2026-02-14 18:19:00,328", "severity": "WARNING", "name": "google_adk.google.adk.runners", "message": "Event from an unknown agent: data_analyst_agent, event id: 2e022edf-3ff9-48f7-b2fb-48d1eb97956f", "trace_id": "9e4c18bfef7a4d74e1248f1b3114684a", "span_id": "6fdc79cebf4958b3", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,328", "severity": "WARNING", "name": "google_adk.google.adk.runners", "message": "Event from an unknown agent: data_analyst_agent, event id: 7b1d468b-06b9-404e-b4fc-312c19fda378", "trace_id": "9e4c18bfef7a4d74e1248f1b3114684a", "span_id": "6fdc79cebf4958b3", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,328", "severity": "WARNING", "name": "google_adk.google.adk.runners", "message": "Event from an unknown agent: data_analyst_agent, event id: 65581701-4df7-431f-8142-5673f56285ff", "trace_id": "9e4c18bfef7a4d74e1248f1b3114684a", "span_id": "6fdc79cebf4958b3", "trace_sampled": true}
[92m18:19:00 - LiteLLM:INFO[0m: utils.py:3748 - 
LiteLLM completion() model= deepseek-ai/DeepSeek-R1-Distill-Qwen-32B; provider = openai
{"timestamp": "2026-02-14 18:19:00,335", "severity": "INFO", "name": "LiteLLM", "message": "\nLiteLLM completion() model= deepseek-ai/DeepSeek-R1-Distill-Qwen-32B; provider = openai", "trace_id": "9e4c18bfef7a4d74e1248f1b3114684a", "span_id": "0eb08c10b43368b0", "trace_sampled": true}
Exception in thread Thread-18 (_asyncio_thread_main):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 460, in make_openai_chat_completion_request
    raise e
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/usr/local/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/openai/_base_client.py", line 1884, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/openai/_base_client.py", line 1669, in request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` does not exist.', 'type': 'NotFoundError', 'param': 'model', 'code': 404}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/litellm/main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 404 - {'error': {'message': 'The model `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` does not exist.', 'type': 'NotFoundError', 'param': 'model', 'code': 404}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 435, in _asyncio_thread_main
    asyncio.run(_invoke_run_async())
  File "/usr/local/lib/python3.12/site-packages/nest_asyncio.py", line 30, in run
    return loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/nest_asyncio.py", line 98, in run_until_complete
    return f.result()
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/asyncio/futures.py", line 202, in result
    raise self._exception.with_traceback(self._exception_tb)
  File "/usr/local/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 428, in _invoke_run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 561, in run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 549, in _run_with_trace
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 778, in _exec_with_plugin
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 538, in execute
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 294, in run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/agents/llm_agent.py", line 468, in _run_async_impl
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 427, in run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 504, in _run_one_step_async
    async for llm_response in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 966, in _call_llm_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 949, in _call_llm_with_tracing
    async for llm_response in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 1184, in _run_and_handle_error
    raise model_error
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 1169, in _run_and_handle_error
    async for llm_response in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/models/lite_llm.py", line 2022, in generate_content_async
    response = await self.llm_client.acompletion(**completion_args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/google/adk/models/lite_llm.py", line 443, in acompletion
    return await acompletion(
           ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/utils.py", line 1915, in wrapper_async
    raise e
  File "/usr/local/lib/python3.12/site-packages/litellm/utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 501, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: NotFoundError: OpenAIException - The model `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` does not exist.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

{"timestamp": "2026-02-14 18:19:00,412", "severity": "WARNING", "name": "Graph.Adapters", "message": "\u26a0\ufe0f Failed to parse Execution Plan JSON: Expecting value: line 1 column 1 (char 0). Passing raw text.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "117376ea7702f4e3", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,423", "severity": "INFO", "name": "EvaluatorNode", "message": "\ud83d\udee1\ufe0f Evaluator: Monitoring execution for execute_trade", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "76f866f3a9ad786f", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,426", "severity": "WARNING", "name": "EvaluatorNode", "message": "\ud83d\uded1 Evaluator Node Detected Violation! Sending Interrupt Signal.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "54baedc24b370746", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,427", "severity": "WARNING", "name": "EvaluatorAgent", "message": "\ud83d\uded1 Evaluator Triggering Intervention: REJECTED: STPA Violation FIN-2: Agent must not execute trade if latency > 200ms; SR 11-7 Violation: Model Confidence 0.0 < 0.95.; ISO 42001 Policy Violation: OPA Denied Action.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "54baedc24b370746", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,430", "severity": "INFO", "name": "EvaluatorNode", "message": "\u2696\ufe0f Evaluator Verdict: REJECTED -> Routing to execution_analyst", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "54baedc24b370746", "trace_sampled": true}
--- [Graph] Calling Execution Analyst (Planner) ---
--- [Loop] Injecting Risk Feedback ---
{"timestamp": "2026-02-14 18:19:00,448", "severity": "WARNING", "name": "google_adk.google.adk.runners", "message": "Event from an unknown agent: data_analyst_agent, event id: 2e022edf-3ff9-48f7-b2fb-48d1eb97956f", "trace_id": "56345a5d746254b5297265be70e3f843", "span_id": "e7665fc6fb61a988", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,448", "severity": "WARNING", "name": "google_adk.google.adk.runners", "message": "Event from an unknown agent: data_analyst_agent, event id: 7b1d468b-06b9-404e-b4fc-312c19fda378", "trace_id": "56345a5d746254b5297265be70e3f843", "span_id": "e7665fc6fb61a988", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,448", "severity": "WARNING", "name": "google_adk.google.adk.runners", "message": "Event from an unknown agent: data_analyst_agent, event id: 65581701-4df7-431f-8142-5673f56285ff", "trace_id": "56345a5d746254b5297265be70e3f843", "span_id": "e7665fc6fb61a988", "trace_sampled": true}
[92m18:19:00 - LiteLLM:INFO[0m: utils.py:3748 - 
LiteLLM completion() model= deepseek-ai/DeepSeek-R1-Distill-Qwen-32B; provider = openai
{"timestamp": "2026-02-14 18:19:00,455", "severity": "INFO", "name": "LiteLLM", "message": "\nLiteLLM completion() model= deepseek-ai/DeepSeek-R1-Distill-Qwen-32B; provider = openai", "trace_id": "56345a5d746254b5297265be70e3f843", "span_id": "85b2c51fdd69e0a4", "trace_sampled": true}
Exception in thread Thread-19 (_asyncio_thread_main):
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 460, in make_openai_chat_completion_request
    raise e
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/usr/local/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/openai/_base_client.py", line 1884, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/openai/_base_client.py", line 1669, in request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` does not exist.', 'type': 'NotFoundError', 'param': 'model', 'code': 404}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/litellm/main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/llms/openai/openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 404 - {'error': {'message': 'The model `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` does not exist.', 'type': 'NotFoundError', 'param': 'model', 'code': 404}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/usr/local/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 435, in _asyncio_thread_main
    asyncio.run(_invoke_run_async())
  File "/usr/local/lib/python3.12/site-packages/nest_asyncio.py", line 30, in run
    return loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/nest_asyncio.py", line 98, in run_until_complete
    return f.result()
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/asyncio/futures.py", line 202, in result
    raise self._exception.with_traceback(self._exception_tb)
  File "/usr/local/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 428, in _invoke_run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 561, in run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 549, in _run_with_trace
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 778, in _exec_with_plugin
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/runners.py", line 538, in execute
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 294, in run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/agents/llm_agent.py", line 468, in _run_async_impl
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 427, in run_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 504, in _run_one_step_async
    async for llm_response in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 966, in _call_llm_async
    async for event in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 949, in _call_llm_with_tracing
    async for llm_response in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 1184, in _run_and_handle_error
    raise model_error
  File "/usr/local/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 1169, in _run_and_handle_error
    async for llm_response in agen:
  File "/usr/local/lib/python3.12/site-packages/google/adk/models/lite_llm.py", line 2022, in generate_content_async
    response = await self.llm_client.acompletion(**completion_args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/google/adk/models/lite_llm.py", line 443, in acompletion
    return await acompletion(
           ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/utils.py", line 1915, in wrapper_async
    raise e
  File "/usr/local/lib/python3.12/site-packages/litellm/utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "/usr/local/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 501, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: NotFoundError: OpenAIException - The model `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` does not exist.

[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new[0m
LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.

{"timestamp": "2026-02-14 18:19:00,534", "severity": "WARNING", "name": "Graph.Adapters", "message": "\u26a0\ufe0f Failed to parse Execution Plan JSON: Expecting value: line 1 column 1 (char 0). Passing raw text.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "55fa7b4909c67170", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,546", "severity": "INFO", "name": "EvaluatorNode", "message": "\ud83d\udee1\ufe0f Evaluator: Monitoring execution for execute_trade", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "58f813021a03cf6f", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,550", "severity": "WARNING", "name": "EvaluatorNode", "message": "\ud83d\uded1 Evaluator Node Detected Violation! Sending Interrupt Signal.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "9c295958db0f5c8d", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,550", "severity": "WARNING", "name": "EvaluatorAgent", "message": "\ud83d\uded1 Evaluator Triggering Intervention: REJECTED: STPA Violation FIN-2: Agent must not execute trade if latency > 200ms; SR 11-7 Violation: Model Confidence 0.0 < 0.95.; ISO 42001 Policy Violation: OPA Denied Action.", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "9c295958db0f5c8d", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,553", "severity": "INFO", "name": "EvaluatorNode", "message": "\u2696\ufe0f Evaluator Verdict: REJECTED -> Routing to execution_analyst", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "9c295958db0f5c8d", "trace_sampled": true}
{"timestamp": "2026-02-14 18:19:00,562", "severity": "WARNING", "name": "opentelemetry.sdk.trace", "message": "Description Recursion limit of 20 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT ignored. Use either `Status` or `(StatusCode, Description)`", "trace_id": "31910e185a3539f6562d17ce4f39441c", "span_id": "9c295958db0f5c8d", "trace_sampled": true}
Traceback (most recent call last):
  File "/app/src/governed_financial_advisor/server.py", line 106, in query_agent
    res = await request.app.state.graph.ainvoke(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/langgraph/pregel/__init__.py", line 2788, in ainvoke
    async for chunk in self.astream(
  File "/usr/local/lib/python3.12/site-packages/langgraph/pregel/__init__.py", line 2677, in astream
    raise GraphRecursionError(msg)
langgraph.errors.GraphRecursionError: Recursion limit of 20 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT
‚ùå Error invoking agent graph: Recursion limit of 20 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT
INFO:     10.128.0.37:19974 - "POST /agent/query HTTP/1.1" 500 Internal Server Error
{"timestamp": "2026-02-14 18:19:02,311", "severity": "ERROR", "name": "opentelemetry.exporter.cloud_trace", "message": "Error while writing to Cloud Trace", "trace_id": null, "span_id": null, "exc_info": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/site-packages/opentelemetry/exporter/cloud_trace/__init__.py\", line 199, in export\n    self.client.batch_write_spans(\n  File \"/usr/local/lib/python3.12/site-packages/google/cloud/trace_v2/services/trace_service/client.py\", line 843, in batch_write_spans\n    rpc(\n  File \"/usr/local/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n    return wrapped_func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py\", line 294, in retry_wrapped_func\n    return retry_target(\n           ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py\", line 156, in retry_target\n    next_sleep = _retry_error_helper(\n                 ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/site-packages/google/api_core/retry/retry_base.py\", line 214, in _retry_error_helper\n    raise final_exc from source_exc\n  File \"/usr/local/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py\", line 147, in retry_target\n    result = target()\n             ^^^^^^^^\n  File \"/usr/local/lib/python3.12/site-packages/google/api_core/timeout.py\", line 130, in func_with_timeout\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/site-packages/google/api_core/grpc_helpers.py\", line 77, in error_remapped_callable\n    raise exceptions.from_grpc_error(exc) from exc\ngoogle.api_core.exceptions.PermissionDenied: 403 The caller does not have permission"}
