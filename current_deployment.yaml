apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "27"
  labels:
    app: governed-financial-advisor
  name: governed-financial-advisor
  namespace: governance-stack
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: governed-financial-advisor
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: governed-financial-advisor
    spec:
      containers:
      - env:
        - name: PORT
          value: "8080"
        - name: DEPLOY_TIMESTAMP
          value: "1770742200"
        - name: GOOGLE_CLOUD_PROJECT
          value: laah-cybernetics
        - name: GOOGLE_CLOUD_LOCATION
          value: local
        - name: REDIS_HOST
          value: redis.governance-stack.svc.cluster.local
        - name: REDIS_PORT
          value: "6379"
        - name: MODEL_FAST
          value: openai/meta-llama/Meta-Llama-3.1-8B-Instruct
        - name: MODEL_REASONING
          value: openai/meta-llama/Meta-Llama-3.1-8B-Instruct
        - name: MODEL_CONSENSUS
          value: openai/meta-llama/Meta-Llama-3.1-8B-Instruct
        - name: VLLM_BASE_URL
          value: http://vllm-service.governance-stack.svc.cluster.local:8000/v1
        - name: VLLM_API_KEY
          value: EMPTY
        - name: OPENAI_API_BASE
          value: http://vllm-service.governance-stack.svc.cluster.local:8000/v1
        - name: OPENAI_API_KEY
          value: EMPTY
        - name: VLLM_FAST_API_BASE
          value: http://vllm-service.governance-stack.svc.cluster.local:8000/v1
        - name: VLLM_REASONING_API_BASE
          value: http://vllm-service.governance-stack.svc.cluster.local:8000/v1
        - name: OPA_URL
          value: http://localhost:8181/v1/data/finance/allow
        - name: LANGSMITH_TRACING
          value: "true"
        - name: LANGSMITH_ENDPOINT
          value: "https://api.smith.langchain.com"
        - name: LANGSMITH_PROJECT
          value: "governed-financial-advisor"
        - name: LANGSMITH_API_KEY
          valueFrom:
            secretKeyRef:
               name: langsmith-secret
               key: api-key
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: "https://api.smith.langchain.com/otel/v1/traces"
        - name: OTEL_EXPORTER_OTLP_HEADERS
          valueFrom:
            secretKeyRef:
               name: langsmith-secret
               key: otel-headers
        - name: TRACE_SAMPLING_RATE
          value: "0.01"
        - name: COLD_TIER_GCS_BUCKET
          value: laah-cybernetics-agent-artifacts
        - name: COLD_TIER_GCS_PREFIX
          value: cold_tier/traces
        - name: MCP_MODE
          value: stdio
        - name: ALPHAVANTAGE_API_KEY
          value: IEDLBOTH6CC0YFQ8
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              key: token
              name: hf-token-secret
        image: gcr.io/laah-cybernetics/financial-advisor:latest
        imagePullPolicy: Always
        name: ingress-agent
        ports:
        - containerPort: 8080
          protocol: TCP
        resources:
          limits:
            cpu: "1"
            memory: 2Gi
          requests:
            cpu: 500m
            memory: 1Gi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      - args:
        - run
        - --server
        - --addr=localhost:8181
        - --config-file=/config/opa_config.yaml
        - /policies/finance_policy.rego
        env:
        - name: REDIS_HOST
          value: redis-master.governance-stack.svc.cluster.local
        - name: OPENAI_API_BASE
          value: http://vllm-service.governance-stack.svc.cluster.local:8000/v1
        - name: OPENAI_API_KEY
          value: EMPTY
        - name: MODEL_FAST
          value: openai/meta-llama/Meta-Llama-3.1-8B-Instruct
        - name: MODEL_REASONING
          value: openai/meta-llama/Meta-Llama-3.1-8B-Instruct
        - name: MODEL_CONSENSUS
          value: openai/meta-llama/Meta-Llama-3.1-8B-Instruct
        image: openpolicyagent/opa:latest-static
        imagePullPolicy: IfNotPresent
        name: opa
        ports:
        - containerPort: 8181
          protocol: TCP
        resources:
          limits:
            cpu: 250m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /policies/finance_policy.rego
          name: policy-volume
          readOnly: true
          subPath: finance_policy.rego
        - mountPath: /config
          name: opa-config-volume
          readOnly: true
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: financial-advisor-sa
      serviceAccountName: financial-advisor-sa
      terminationGracePeriodSeconds: 30
      volumes:
      - name: policy-volume
        secret:
          defaultMode: 420
          secretName: finance-policy-rego
      - name: opa-config-volume
        secret:
          defaultMode: 420
          secretName: opa-configuration
